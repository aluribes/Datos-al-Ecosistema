"""
02_socrata_bucaramanga_to_parquet.py
====================================

Convierte y limpia archivos JSON de Socrata a Parquet para la capa Silver.

Entrada (Bronze):
    data/bronze/socrata_api/bucaramanga_delictiva_150.json
    data/bronze/socrata_api/bucaramanga_delitos_40.json
    data/bronze/socrata_api/delitos_informaticos.json

Salida (Silver):
    data/silver/socrata_api/bucaramanga_delitos.parquet       # Bucaramanga unificado y sin duplicados
    data/silver/socrata_api/delitos_informaticos.parquet      # Delitos inform√°ticos limpio

Transformaciones principales:
    - Columnas en min√∫scula y formato snake_case (nombre_columna)
    - Unificaci√≥n de las dos bases de Bucaramanga y eliminaci√≥n de duplicados
    - Normalizaci√≥n de nombres de columnas para alinearlos con otros datasets:
        * cod_mun, cod_muni, cod_mpio, codigo_mun -> codigo_municipio
"""

from pathlib import Path
from typing import List

import pandas as pd

# === CONFIGURACI√ìN ===
# Subimos un nivel desde scripts/ para llegar a la ra√≠z del proyecto
BASE_DIR = Path(__file__).resolve().parent.parent

BRONZE_DIR = BASE_DIR / "data" / "bronze" / "socrata_api"
SILVER_DIR = BASE_DIR / "data" / "silver" / "socrata_api"

# Archivos a procesar (sin extensi√≥n)
BUCARAMANGA_STEMS: List[str] = [
    "bucaramanga_delictiva_150",
    "bucaramanga_delitos_40",
]

DELITOS_INF_STEM = "delitos_informaticos"

BUCARAMANGA_OUTPUT = "bucaramanga_delitos.parquet"
DELITOS_INF_OUTPUT = "delitos_informaticos.parquet"


# =========================================================
# Utilidades generales
# =========================================================

def ensure_folder(path: Path) -> None:
    """Crea directorio si no existe."""
    path.mkdir(parents=True, exist_ok=True)


def check_exists(path: Path, label: str | None = None) -> None:
    """Verifica que un archivo exista antes de procesarlo."""
    if not path.exists():
        msg = f"‚ùå ERROR: No se encontr√≥ el archivo requerido:\n{path}"
        if label is not None:
            msg += f"\n(dataset: {label})"
        print(msg)
        raise FileNotFoundError(msg)
    print(f"‚úî Archivo encontrado: {path}")


def to_snake_case(name: str) -> str:
    """
    Convierte un nombre de columna a snake_case en min√∫sculas.
    Ejemplos:
        "COD_MUN"        -> "cod_mun"
        "Cod Mun"        -> "cod_mun"
        "C√≥digo Municipio" -> "c√≥digo_municipio"
    (sin eliminar tildes, solo formateo b√°sico)
    """
    # Pasar a string por seguridad
    text = str(name)
    # Quitar espacios al inicio/fin
    text = text.strip()
    # Reemplazar espacios y separadores comunes por guion bajo
    for sep in [" ", "-", "/", "."]:
        text = text.replace(sep, "_")
    # Normalizar dobles guiones bajos
    while "__" in text:
        text = text.replace("__", "_")
    # A min√∫sculas
    return text.lower()


def standardize_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """
    Estandariza los nombres de columnas:
        - min√∫scula
        - snake_case
        - mapea columnas espec√≠ficas a nombres est√°ndar del modelo (p.ej. codigo_municipio)
    """
    # 1. snake_case gen√©rico
    df = df.copy()
    new_cols = {col: to_snake_case(col) for col in df.columns}
    df = df.rename(columns=new_cols)

    # 2. Mapeo espec√≠fico para alinearse con otros datasets
    #    (puedes ir ajustando este diccionario seg√∫n veas m√°s columnas)
    rename_map = {
        "cod_mun": "codigo_municipio",
        "cod_muni": "codigo_municipio",
        "cod_mpio": "codigo_municipio",
        "codigo_mun": "codigo_municipio",
        "codigo_dane_municipio": "codigo_municipio",
        # Por si viniera algo como "cod_municipio"
        "cod_municipio": "codigo_municipio",
    }

    df = df.rename(columns={old: new for old, new in rename_map.items() if old in df.columns})

    return df


# =========================================================
# Carga y limpieza de JSON
# =========================================================

def load_and_clean_json(stem: str) -> pd.DataFrame:
    """
    Lee un JSON Bronze, estandariza nombres de columnas y retorna el DataFrame.
    No aplica filtros de filas, solo limpieza de nombres.
    """
    input_path = BRONZE_DIR / f"{stem}.json"
    check_exists(input_path, label=stem)

    print(f"\n‚û§ Cargando dataset: {stem}")
    print(f"   Leyendo JSON desde: {input_path}")

    df = pd.read_json(input_path)

    print(f"   Registros raw: {len(df):,}")
    print(f"   Columnas raw: {list(df.columns)}")

    df = standardize_column_names(df)

    print(f"   Columnas estandarizadas: {list(df.columns)}")

    return df


# =========================================================
# Procesos espec√≠ficos
# =========================================================

def process_bucaramanga() -> None:
    """
    Procesa los dos datasets de Bucaramanga:
        - bucaramanga_delictiva_150
        - bucaramanga_delitos_40

    Unifica ambos en un solo DataFrame, elimina duplicados
    y los guarda en un √∫nico Parquet en Silver.
    """
    print("\n" + "-" * 60)
    print("üèô  PROCESANDO BUCARAMANGA (UNIFICAR + LIMPIAR)")
    print("-" * 60)

    dataframes: list[pd.DataFrame] = []

    for stem in BUCARAMANGA_STEMS:
        df_stem = load_and_clean_json(stem)

        if df_stem.empty:
            print(f"   ‚ö† Dataset vac√≠o: {stem}")
        else:
            print(f"   ‚úî Dataset {stem} con {len(df_stem):,} filas")
            dataframes.append(df_stem)

    if not dataframes:
        print("   ‚ùå No hay datos de Bucaramanga para procesar.")
        return

    # Unificar y eliminar duplicados
    df_bucaramanga = pd.concat(dataframes, ignore_index=True)

    rows_before = len(df_bucaramanga)
    df_bucaramanga = df_bucaramanga.drop_duplicates()
    rows_after = len(df_bucaramanga)

    print(f"\n   Filas unificadas antes de eliminar duplicados: {rows_before:,}")
    print(f"   Filas despu√©s de eliminar duplicados:         {rows_after:,}")

    ensure_folder(SILVER_DIR)
    output_path = SILVER_DIR / BUCARAMANGA_OUTPUT

    df_bucaramanga.to_parquet(output_path, engine="fastparquet", index=False)

    print(f"\n   ‚úÖ Bucaramanga unificado guardado en: {output_path}")
    print(f"      Registros finales: {len(df_bucaramanga):,}")
    print(f"      Columnas: {list(df_bucaramanga.columns)}")


def process_delitos_informaticos() -> None:
    """
    Procesa el dataset de delitos inform√°ticos:
        - Limpia nombres de columnas (snake_case, min√∫scula)
        - Ajusta nombres como codigo_municipio si aplica
        - Guarda el resultado en Silver como Parquet
    """
    print("\n" + "-" * 60)
    print("üíª  PROCESANDO DELITOS INFORM√ÅTICOS")
    print("-" * 60)

    df_inf = load_and_clean_json(DELITOS_INF_STEM)

    if df_inf.empty:
        print("   ‚ö† Dataset de delitos inform√°ticos vac√≠o.")
        return

    ensure_folder(SILVER_DIR)
    output_path = SILVER_DIR / DELITOS_INF_OUTPUT

    df_inf.to_parquet(output_path, engine="fastparquet", index=False)

    print(f"\n   ‚úÖ Delitos inform√°ticos guardado en: {output_path}")
    print(f"      Registros: {len(df_inf):,}")
    print(f"      Columnas: {list(df_inf.columns)}")


# =========================================================
# main
# =========================================================

def main() -> None:
    """Funci√≥n principal del script."""
    print("=" * 60)
    print("02 - SOCRATA (BUCARAMANGA + DELITOS INFORM√ÅTICOS) ‚Üí SILVER")
    print("=" * 60)

    process_bucaramanga()
    process_delitos_informaticos()

    print("\n" + "=" * 60)
    print("‚úî Proceso de conversi√≥n y limpieza completado")
    print("=" * 60)


if __name__ == "__main__":
    main()
