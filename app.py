# app.py
"""
Dashboard de Seguridad Ciudadana - Santander
============================================

Usa las tablas de data/gold/dashboard:

    - metas.parquet
    - mandatos.parquet
    - poblacion_santander.parquet
    - policia_santander.parquet
    - municipios.parquet

Simula el modelo relacional uniÃ©ndolas en memoria para:

    - Dashboard descriptivo
    - Chat de datos (agente sencillo)
    - Modelo predictivo baseline (promedio histÃ³rico)
"""

from pathlib import Path
from typing import Dict, List, Tuple

import altair as alt
import pandas as pd
import streamlit as st

# ============================================================
# CONFIGURACIÃ“N GENERAL
# ============================================================

st.set_page_config(
    page_title="Seguridad Ciudadana - Santander",
    layout="wide",
)

DATA_DIR = Path("data/gold/dashboard")


# ============================================================
# 1. Carga de datos y construcciÃ³n del modelo integrado
# ============================================================

@st.cache_data(show_spinner=True)
def load_base_tables() -> Dict[str, pd.DataFrame]:
    """Carga las tablas base del dashboard desde data/gold/dashboard."""
    metas = pd.read_parquet(DATA_DIR / "metas.parquet")
    mandatos = pd.read_parquet(DATA_DIR / "mandatos.parquet")
    poblacion = pd.read_parquet(DATA_DIR / "poblacion_santander.parquet")
    policia = pd.read_parquet(DATA_DIR / "policia_santander.parquet")
    municipios = pd.read_parquet(DATA_DIR / "municipios.parquet")

    # Normalizar nombres de columnas (quitar espacios)
    for df in (metas, mandatos, poblacion, policia, municipios):
        df.columns = [c.strip() for c in df.columns]

    return {
        "metas": metas,
        "mandatos": mandatos,
        "poblacion": poblacion,
        "policia": policia,
        "municipios": municipios,
    }


def build_integrated_df(
    metas: pd.DataFrame,
    mandatos: pd.DataFrame,
    poblacion: pd.DataFrame,
    policia: pd.DataFrame,
    municipios: pd.DataFrame,
) -> pd.DataFrame:
    """
    Construye un DataFrame integrado a nivel de hecho policial,
    uniendo policia + municipios + poblaciÃ³n + mandatos + metas.
    """
    df = policia.copy()

    # Join dimensiÃ³n espacial (municipios)
    df = df.merge(
        municipios[
            [
                "codigo_municipio",
                "codigo_departamento",
                "departamento",
                "municipio",
            ]
        ],
        on="codigo_municipio",
        how="left",
        suffixes=("", "_muni"),
    )

    # Join poblaciÃ³n (para tasas)
    df = df.merge(
        poblacion[["codigo_municipio", "anio", "n_poblacion"]],
        on=["codigo_municipio", "anio"],
        how="left",
    )

    # Join mandatos y metas
    df = df.merge(mandatos, on="anio", how="left")  # agrega "mandato"
    df = df.merge(metas, on="mandato", how="left")  # agrega metas y presupuesto

    # Calcular tasa por 100.000 habitantes
    df["tasa_100k"] = df["cantidad"] / df["n_poblacion"] * 1e5

    # Tipos bÃ¡sicos y normalizaciÃ³n
    df["anio"] = df["anio"].astype(int)
    df["delito"] = df["delito"].astype(str).str.upper()
    df["municipio"] = df["municipio"].astype(str).str.upper()

    return df


# ============================================================
# 2. Helpers genÃ©ricos (normalizaciÃ³n y agregaciones)
# ============================================================

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza nombres de columnas (strip) y retorna copia."""
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    return df


def aggregate_delito(
    df: pd.DataFrame,
    crime_name: str,
    meta_col: str,
) -> Tuple[int, float]:
    """
    Agrega casos y meta a nivel departamental para un delito concreto.
    Devuelve (casos_totales, meta_anual).
    """
    df_crime = df[df["delito"] == crime_name].copy()
    cases = int(df_crime["cantidad"].sum()) if not df_crime.empty else 0

    meta = 0.0
    if meta_col in df_crime.columns and not df_crime[meta_col].dropna().empty:
        meta = float(df_crime[meta_col].dropna().iloc[0])

    return cases, meta


def build_delta_text(actual: int, meta: float) -> str:
    """Construye un texto de delta respecto a la meta."""
    if meta == 0:
        return "Sin meta"
    diff = actual - meta
    perc = diff / meta * 100
    arrow = "â†‘" if diff > 0 else "â†“"
    return f"{arrow} {perc:,.1f}% vs meta"


# ============================================================
# 3. TAB 1 - Dashboard descriptivo
# ============================================================

def dashboard_tab(df_integrated: pd.DataFrame, mandatos: pd.DataFrame) -> None:
    """Construye la pestaÃ±a principal del dashboard descriptivo."""
    st.subheader("ðŸ“Š Dashboard de Seguridad Ciudadana - Santander")

    # ---------------------------
    # Filtros en sidebar
    # ---------------------------
    with st.sidebar:
        st.header("Filtros")

        years = sorted(mandatos["anio"].unique())
        year_selected = st.selectbox("AÃ±o de mandato", years, index=len(years) - 1)

        mandatos_sel = mandatos.loc[
            mandatos["anio"] == year_selected, "mandato"
        ].unique()
        mandato_selected = mandatos_sel[0] if len(mandatos_sel) > 0 else None

        df_year = df_integrated[df_integrated["anio"] == year_selected].copy()

        municipalities_available = sorted(df_year["municipio"].dropna().unique())
        muni_selected = st.multiselect(
            "Municipios",
            options=municipalities_available,
            default=municipalities_available,
        )

        crimes_available = sorted(df_year["delito"].dropna().unique())
        crime_selected = st.multiselect(
            "Tipos de delito",
            options=crimes_available,
            default=crimes_available,
        )

    # Aplicar filtros
    mask = df_integrated["anio"] == year_selected
    if muni_selected:
        mask &= df_integrated["municipio"].isin(muni_selected)
    if crime_selected:
        mask &= df_integrated["delito"].isin(crime_selected)

    df_f = df_integrated[mask].copy()

    if df_f.empty:
        st.warning("No hay datos para la combinaciÃ³n de filtros seleccionada.")
        return

    # ---------------------------
    # KPIs generales
    # ---------------------------
    st.markdown(f"### Mandato **{mandato_selected}** â€“ AÃ±o **{year_selected}**")

    col_kpi1, col_kpi2, col_kpi3 = st.columns(3)

    with col_kpi1:
        total_cases = int(df_f["cantidad"].sum())
        st.metric(
            "Total de casos (todas las categorÃ­as)",
            f"{total_cases:,}".replace(",", "."),
        )

    with col_kpi2:
        n_municipios = df_f["codigo_municipio"].nunique()
        st.metric("Municipios con registros", n_municipios)

    with col_kpi3:
        total_pop = int(df_f["n_poblacion"].fillna(0).sum())
        st.metric("PoblaciÃ³n cubierta", f"{total_pop:,}".replace(",", "."))

    st.markdown("---")

    # ---------------------------
    # KPIs por delito vs meta
    # ---------------------------
    st.markdown("### Metas departamentales vs realidad")

    # Homicidios
    hom_cases, hom_meta = aggregate_delito(df_f, "HOMICIDIOS", "meta_homicidios")

    # Hurtos (distintos alias posibles)
    hurto_aliases = ["HURTOS", "HURTO", "HURTO_PERSONAS"]
    hurto_cases = int(df_f[df_f["delito"].isin(hurto_aliases)]["cantidad"].sum())
    hurto_meta = 0.0
    if "meta_hurtos" in df_f.columns and not df_f["meta_hurtos"].dropna().empty:
        hurto_meta = float(df_f["meta_hurtos"].dropna().iloc[0])

    # Lesiones
    lesions_cases, lesions_meta = aggregate_delito(df_f, "LESIONES", "meta_lesiones")

    kpi_cols = st.columns(3)

    with kpi_cols[0]:
        st.metric(
            "Homicidios (casos vs meta)",
            f"{hom_cases:,}".replace(",", "."),
            delta=build_delta_text(hom_cases, hom_meta),
        )

    with kpi_cols[1]:
        st.metric(
            "Hurtos (casos vs meta)",
            f"{hurto_cases:,}".replace(",", "."),
            delta=build_delta_text(hurto_cases, hurto_meta),
        )

    with kpi_cols[2]:
        st.metric(
            "Lesiones (casos vs meta)",
            f"{lesions_cases:,}".replace(",", "."),
            delta=build_delta_text(lesions_cases, lesions_meta),
        )

    st.markdown("---")

    # ---------------------------
    # GrÃ¡fico: distribuciÃ³n por municipio
    # ---------------------------
    st.markdown("### DistribuciÃ³n de casos por municipio")

    df_muni = (
        df_f.groupby("municipio", as_index=False)["cantidad"]
        .sum()
        .sort_values("cantidad", ascending=False)
    )

    chart_muni = (
        alt.Chart(df_muni)
        .mark_bar()
        .encode(
            x=alt.X("cantidad:Q", title="NÃºmero de casos"),
            y=alt.Y("municipio:N", sort="-x", title="Municipio"),
            tooltip=["municipio", "cantidad"],
        )
        .properties(height=400)
    )

    st.altair_chart(chart_muni, use_container_width=True)

    st.markdown("---")

    # ---------------------------
    # GrÃ¡fico: distribuciÃ³n por tipo de delito
    # ---------------------------
    st.markdown("### DistribuciÃ³n por tipo de delito")

    df_crime = (
        df_f.groupby("delito", as_index=False)["cantidad"]
        .sum()
        .sort_values("cantidad", ascending=False)
    )

    chart_crime = (
        alt.Chart(df_crime)
        .mark_bar()
        .encode(
            x=alt.X("cantidad:Q", title="NÃºmero de casos"),
            y=alt.Y("delito:N", sort="-x", title="Delito"),
            tooltip=["delito", "cantidad"],
        )
        .properties(height=400)
    )

    st.altair_chart(chart_crime, use_container_width=True)

    st.markdown("---")

    # ---------------------------
    # Tendencia histÃ³rica (todos los aÃ±os)
    # ---------------------------
    st.markdown("### Tendencia histÃ³rica (todos los aÃ±os)")

    mask_hist = df_integrated["delito"].isin(crime_selected) if crime_selected else True
    if muni_selected:
        mask_hist &= df_integrated["municipio"].isin(muni_selected)

    df_hist = (
        df_integrated[mask_hist]
        .groupby("anio", as_index=False)["cantidad"]
        .sum()
        .sort_values("anio")
    )

    chart_hist = (
        alt.Chart(df_hist)
        .mark_line(point=True)
        .encode(
            x=alt.X("anio:O", title="AÃ±o"),
            y=alt.Y("cantidad:Q", title="Casos totales"),
            tooltip=["anio", "cantidad"],
        )
        .properties(height=350)
    )

    st.altair_chart(chart_hist, use_container_width=True)

    st.markdown("---")

    st.markdown("### Detalle de registros (muestra)")
    st.dataframe(df_f.head(200))


# ============================================================
# 4. TAB 2 - Chatbot / Agente de datos
# ============================================================

def explain_stats_agent(df: pd.DataFrame, question: str) -> str:
    """
    Agente sencillo que:
        - Detecta delito, municipio y aÃ±o (si se menciona).
        - Calcula casos y tasa.
        - Explica en lenguaje natural y aÃ±ade rutas de atenciÃ³n.
    """
    df = normalize_columns(df)

    text = question.lower()

    # --- Detectar delito por palabras clave ---
    crime_map = {
        "homicid": "HOMICIDIOS",
        "asesin": "HOMICIDIOS",
        "hurto": "HURTOS",
        "robo": "HURTOS",
        "lesion": "LESIONES",
        "violencia intrafamiliar": "VIOLENCIA INTRAFAMILIAR",
        "intrafamiliar": "VIOLENCIA INTRAFAMILIAR",
        "sexual": "DELITOS SEXUALES",
        "informatic": "DELITOS INFORMÃTICOS",
    }
    crime_detected = None
    for key, crime in crime_map.items():
        if key in text:
            crime_detected = crime
            break

    # --- Detectar municipio buscando coincidencia exacta del nombre ---
    muni_detected = None
    for muni in df["municipio"].dropna().unique():
        if str(muni).lower() in text:
            muni_detected = muni
            break

    # --- Detectar aÃ±o (si hay un nÃºmero de 4 dÃ­gitos en rango) ---
    year_detected = None
    years_valid = df["anio"].unique().tolist()
    for token in text.split():
        if token.isdigit() and len(token) == 4:
            year_candidate = int(token)
            if year_candidate in years_valid:
                year_detected = year_candidate
                break

    if year_detected is None:
        year_detected = int(df["anio"].max())

    # --- Construir filtro ---
    df_q = df[df["anio"] == year_detected].copy()
    filtros_txt: List[str] = [f"aÃ±o = **{year_detected}**"]

    if crime_detected is not None:
        df_q = df_q[df_q["delito"] == crime_detected]
        filtros_txt.append(f"delito = **{crime_detected}**")

    if muni_detected is not None:
        df_q = df_q[df_q["municipio"] == muni_detected]
        filtros_txt.append(f"municipio = **{muni_detected}**")

    if df_q.empty:
        resumen = (
            "Con la informaciÃ³n disponible no encontrÃ© registros que coincidan con tu pregunta. "
            "Prueba preguntando solo por tipo de delito o solo por municipio."
        )
    else:
        total_cases = int(df_q["cantidad"].sum())
        tasa_prom = float(df_q["tasa_100k"].mean()) if "tasa_100k" in df_q.columns else None

        # Comparar con aÃ±o anterior si existe
        trend_text = ""
        prev_year = year_detected - 1
        if prev_year in years_valid:
            df_prev = df[
                (df["anio"] == prev_year)
                & (df_q["delito"].unique().tolist() if crime_detected else [True])
            ].copy()
            if muni_detected is not None:
                df_prev = df_prev[df_prev["municipio"] == muni_detected]

            if not df_prev.empty:
                prev_cases = int(df_prev["cantidad"].sum())
                diff = total_cases - prev_cases
                sign = "mÃ¡s" if diff > 0 else "menos" if diff < 0 else "igual nÃºmero de"
                trend_text = (
                    f" En comparaciÃ³n con {prev_year}, hay **{abs(diff):,} casos {sign}**."
                    if diff != 0
                    else f" En comparaciÃ³n con {prev_year}, se mantiene un nivel similar de casos."
                )

        filtros_str = ", ".join(filtros_txt)
        if tasa_prom is not None and not pd.isna(tasa_prom):
            resumen = (
                f"Con los filtros {filtros_str}, se registran **{total_cases:,} casos** "
                f"y una **tasa promedio de {tasa_prom:,.2f} por cada 100.000 habitantes**."
            )
        else:
            resumen = (
                f"Con los filtros {filtros_str}, se registran **{total_cases:,} casos** "
                f"(no tengo columna de tasa disponible)."
            )

        if trend_text:
            resumen += trend_text

    rutas = """
**Rutas de atenciÃ³n recomendadas**

- Emergencias y situaciones en curso: **lÃ­nea 123** (PolicÃ­a Nacional).
- Violencia intrafamiliar y delitos sexuales:
  - **ComisarÃ­as de Familia** del municipio.
  - **LÃ­nea 155** (orientaciÃ³n a mujeres).
- Denuncias formales:
  - **FiscalÃ­a General de la NaciÃ³n** (URI / CAI / Casas de Justicia).
  - Estaciones de PolicÃ­a mÃ¡s cercanas.

Recuerda que estos datos son estadÃ­sticos y no reemplazan las rutas oficiales de atenciÃ³n inmediata.
"""

    return resumen + "\n\n" + rutas


def chatbot_tab(df_integrated: pd.DataFrame) -> None:
    """PestaÃ±a de chatbot/agente de datos."""
    st.subheader("ðŸ¤– Chat comunitario de datos y rutas de atenciÃ³n")

    st.markdown(
        """
Este chatbot funciona como un **agente sobre los datos**:  
lee tu pregunta, filtra el dataset y genera un resumen estadÃ­stico
junto con rutas de atenciÃ³n.

Ejemplos de preguntas:

- *"Â¿CÃ³mo estÃ¡n los homicidios en Bucaramanga en 2022?"*  
- *"Â¿QuÃ© pasa con los hurtos en Santander el Ãºltimo aÃ±o?"*  
- *"Â¿CÃ³mo van los delitos sexuales en el departamento?"*
"""
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Historial
    with st.container():
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                st.markdown(f"**TÃº:** {msg['content']}")
            else:
                st.markdown(f"**Asistente:** {msg['content']}")

    question = st.text_input("Escribe tu pregunta:", value="", max_chars=300)

    col_btn1, col_btn2 = st.columns([1, 1])

    with col_btn1:
        if st.button("Enviar", type="primary") and question.strip():
            st.session_state.chat_history.append(
                {"role": "user", "content": question}
            )
            answer = explain_stats_agent(df_integrated, question)
            st.session_state.chat_history.append(
                {"role": "assistant", "content": answer}
            )
            st.experimental_rerun()

    with col_btn2:
        if st.button("ðŸ—‘ï¸ Limpiar conversaciÃ³n"):
            st.session_state.chat_history = []
            st.experimental_rerun()


# ============================================================
# 5. MODELOS PREDICTIVOS / ANALÃTICA AVANZADA
# ============================================================

# Carpeta donde vas a guardar los datasets de modelado
# (ajusta la ruta si los tienes en otro lado)
MODEL_DIR = Path("data/model")


@st.cache_data(show_spinner=True)
def load_model_datasets() -> dict:
    """
    Carga los datasets de modelado (si existen).
    No rompe la app si alguno todavÃ­a no estÃ¡ creado.
    """
    files = {
        "classification_dominant": "classification_dominant_dataset.parquet",
        "classification_event": "classification_event_dataset.parquet",
        "classification_monthly": "classification_monthly_dataset.parquet",
        "clustering_geo": "clustering_geo_dataset.parquet",
        "regression_annual": "regression_annual_dataset.parquet",
        "regression_monthly": "regression_monthly_dataset.parquet",
        "regression_timeseries": "regression_timeseries_dataset.parquet",
    }

    datasets: dict[str, pd.DataFrame | None] = {}
    for key, fname in files.items():
        path = MODEL_DIR / fname
        if path.exists():
            datasets[key] = pd.read_parquet(path)
        else:
            datasets[key] = None
    return datasets


def simple_baseline_prediction(
    df: pd.DataFrame,
    municipio: str,
    delito: str,
    target_year: int,
) -> tuple[float | None, str | pd.DataFrame]:
    """
    Baseline muy simple:
        - Usa el dataset integrado (no los datasets de modelado).
        - Toma los Ãºltimos 3 aÃ±os antes del aÃ±o objetivo.
        - PredicciÃ³n = promedio de casos de esos 3 aÃ±os.
    """
    df = df.copy()

    df_f = df[(df["municipio"] == municipio) & (df["delito"] == delito)].copy()
    if df_f.empty:
        return None, "No hay datos histÃ³ricos para ese municipio y delito."

    df_hist = df_f[df_f["anio"] < target_year]
    if df_hist.empty:
        return None, "No hay aÃ±os anteriores al objetivo para calcular un promedio."

    df_agg = (
        df_hist.groupby("anio", as_index=False)["cantidad"]
        .sum()
        .sort_values("anio")
    )

    pred = float(df_agg["cantidad"].tail(3).mean())
    detalle = df_agg.rename(columns={"anio": "AÃ±o", "cantidad": "Casos"})

    return pred, detalle


def prediction_tab(df_integrated: pd.DataFrame) -> None:
    """
    PestaÃ±a de modelos predictivos, organizada en dos bloques:

    1. Explorador de datasets de modelado (clasificaciÃ³n, regresiÃ³n, clustering,
       series de tiempo). AquÃ­ se cargan y se muestran los datasets que
       utilizarÃ¡n tus futuros modelos.

    2. Baseline histÃ³rico simple (ya funcional) que calcula un pronÃ³stico
       usando el dataset integrado actual.
    """
    st.subheader("ðŸ”® MÃ³dulos predictivos y datasets de modelado")

    # ----------------------------------------------
    # 5.1 Explorador de datasets de modelado
    # ----------------------------------------------
    ml_data = load_model_datasets()

    st.markdown(
        """
Esta secciÃ³n organiza los datasets de modelado que vas a usar:

- **ClasificaciÃ³n** (dominante, evento a evento, riesgo mensual)
- **RegresiÃ³n** (anual, mensual)
- **Series de tiempo** (forecast puro)
- **Clustering geoespacial**

Por ahora actÃºa como **explorador y documentaciÃ³n viva** de tus datasets.
Cuando tengas los modelos entrenados, aquÃ­ mismo podrÃ¡s conectarlos.
"""
    )

    module = st.radio(
        "Selecciona el mÃ³dulo a explorar",
        [
            "ClasificaciÃ³n â€“ Delito / arma dominante (dominant_dataset)",
            "ClasificaciÃ³n â€“ Evento a evento (event_dataset)",
            "ClasificaciÃ³n â€“ Riesgo mensual (monthly_dataset)",
            "RegresiÃ³n â€“ Tendencia anual (annual_dataset)",
            "RegresiÃ³n â€“ Forecast mensual (monthly_dataset)",
            "Series de tiempo â€“ Forecast puro (timeseries_dataset)",
            "Clustering geoespacial-delictivo (geo_dataset)",
        ],
        index=4,  # por defecto: regresiÃ³n mensual
    )

    # Helper para mostrar info bÃ¡sica de un dataset
    def show_dataset_info(df: pd.DataFrame | None, nombre_archivo: str, descripcion: str) -> None:
        st.markdown(f"**Archivo:** `{nombre_archivo}`")
        st.markdown(descripcion)

        if df is None:
            st.warning("âš ï¸ AÃºn no encontrÃ© este archivo en la carpeta `data/model`. "
                       "Cuando lo generes, se cargarÃ¡ automÃ¡ticamente.")
            return

        st.info(f"Filas: **{len(df):,}** â€“ Columnas: **{len(df.columns)}**")
        with st.expander("Ver columnas disponibles"):
            st.write(list(df.columns))

        with st.expander("Vista previa (primeras filas)"):
            st.dataframe(df.head(50))

    # SegÃºn el mÃ³dulo seleccionado, mostramos el dataset correspondiente
    if module.startswith("ClasificaciÃ³n â€“ Delito / arma dominante"):
        show_dataset_info(
            ml_data["classification_dominant"],
            "classification_dominant_dataset.parquet",
            """
**Uso previsto:**

- PredicciÃ³n del **delito dominante** por municipioâ€“aÃ±oâ€“mes.
- PredicciÃ³n del **arma/medio dominante**.
- AnÃ¡lisis de municipios que cambian de delito dominante en el tiempo.

**Preguntas que responde:**

- Â¿CuÃ¡l serÃ¡ el delito mÃ¡s frecuente el prÃ³ximo mes?
- Â¿QuÃ© arma/medio serÃ¡ mÃ¡s usado?
- Â¿QuÃ© municipios cambian su patrÃ³n dominante?
""",
        )

    elif module.startswith("ClasificaciÃ³n â€“ Evento a evento"):
        show_dataset_info(
            ml_data["classification_event"],
            "classification_event_dataset.parquet",
            """
**Uso previsto:**

- ClasificaciÃ³n multiclase a nivel de **evento delictivo**.
- PredicciÃ³n del tipo de delito y/o perfil (agresor, vÃ­ctima).
- Probabilidad de ocurrencia segÃºn contexto (fecha, municipio, demografÃ­a).

**Preguntas que responde:**

- Â¿QuÃ© tipo de delito es mÃ¡s probable en cierto contexto?
- Â¿El perfil asociado se puede predecir?
- Â¿QuÃ© factores temporales influyen en cada delito?
""",
        )

    elif module.startswith("ClasificaciÃ³n â€“ Riesgo mensual"):
        show_dataset_info(
            ml_data["classification_monthly"],
            "classification_monthly_dataset.parquet",
            """
**Uso previsto:**

- ClasificaciÃ³n de **riesgo mensual** (Bajo / Medio / Alto) por municipio.
- ClasificaciÃ³n binaria (incremento / no incremento).

**Preguntas que responde:**

- Â¿QuÃ© municipios estÃ¡n en riesgo alto el prÃ³ximo mes?
- Â¿En quÃ© municipios aumentarÃ¡n los delitos?
- Â¿QuÃ© variables explican mejor el riesgo mensual?

**Utilidad:** SemÃ¡foros delictivos y alertas tempranas para el tablero.
""",
        )

    elif module.startswith("RegresiÃ³n â€“ Tendencia anual"):
        show_dataset_info(
            ml_data["regression_annual"],
            "regression_annual_dataset.parquet",
            """
**Uso previsto:**

- Modelos de **regresiÃ³n anual** por municipio.
- PredicciÃ³n de delitos anuales y tendencias a largo plazo.

**Preguntas que responde:**

- Â¿CuÃ¡l serÃ¡ la cantidad de delitos el prÃ³ximo aÃ±o?
- Â¿QuÃ© municipios tienen tendencias ascendentes o descendentes?
- Â¿QuÃ© factores influyen en la variaciÃ³n anual?

**Utilidad:** PlaneaciÃ³n estratÃ©gica e informes institucionales.
""",
        )

    elif module.startswith("RegresiÃ³n â€“ Forecast mensual"):
        show_dataset_info(
            ml_data["regression_monthly"],
            "regression_monthly_dataset.parquet",
            """
**Uso previsto:**

- RegresiÃ³n mensual pura con lags, ventanas mÃ³viles y estacionalidad.
- PredicciÃ³n del nÃºmero **exacto** de delitos el prÃ³ximo mes.

**Preguntas que responde:**

- Â¿CuÃ¡ntos delitos habrÃ¡ el siguiente mes?
- Â¿CÃ³mo varÃ­a el volumen a lo largo del aÃ±o?
- Â¿QuÃ© variables explican mejor la fluctuaciÃ³n mensual?

**Utilidad:** Forecast detallado para el tablero y alertas numÃ©ricas.
""",
        )

    elif module.startswith("Series de tiempo â€“ Forecast puro"):
        show_dataset_info(
            ml_data["regression_timeseries"],
            "regression_timeseries_dataset.parquet",
            """
**Uso previsto:**

- Modelos clÃ¡sicos de series de tiempo (ARIMA, Prophet, LSTMs, etc.).
- Forecast mes a mes con foco total en la dinÃ¡mica temporal.

**Preguntas que responde:**

- Â¿CÃ³mo evolucionarÃ¡n los delitos mes a mes?
- Â¿Existen patrones estacionales fuertes?
- Â¿QuÃ© municipios presentan mayor periodicidad?

**Utilidad:** Forecast robusto orientado al tiempo.
""",
        )

    elif module.startswith("Clustering geoespacial-delictivo"):
        show_dataset_info(
            ml_data["clustering_geo"],
            "clustering_geo_dataset.parquet",
            """
**Uso previsto:**

- Clustering geoespacialâ€“delictivo (KMeans, HDBSCAN, etc.).
- AgrupaciÃ³n de municipios segÃºn perfil delictivo, demografÃ­a y geografÃ­a.

**Preguntas que responde:**

- Â¿QuÃ© municipios se parecen entre sÃ­ en su comportamiento?
- Â¿QuÃ© grupos presentan mayor concentraciÃ³n de delitos?
- Â¿Existen patrones urbanoâ€“rural?

**Utilidad:** PolÃ­ticas diferenciadas por tipo de municipio y mapas de clusters.
""",
        )

    st.markdown("---")
    st.subheader("ðŸ§ª Baseline histÃ³rico rÃ¡pido (demo de predicciÃ³n)")

    # ----------------------------------------------
    # 5.2 Baseline histÃ³rico (sigue usando df_integrated)
    # ----------------------------------------------
    df = df_integrated.copy()

    municipios = sorted(df["municipio"].dropna().unique())
    delitos = sorted(df["delito"].dropna().unique())

    col1, col2 = st.columns(2)
    with col1:
        muni_sel = st.selectbox("Municipio", municipios)
    with col2:
        delito_sel = st.selectbox("Tipo de delito", delitos)

    year_min = int(df["anio"].min())
    year_max = int(df["anio"].max())

    target_year = st.number_input(
        "AÃ±o a predecir (baseline)",
        min_value=year_max + 1,
        max_value=year_max + 10,
        value=year_max + 1,
        step=1,
    )

    if st.button("Calcular predicciÃ³n baseline", type="primary"):
        pred, detail = simple_baseline_prediction(
            df,
            municipio=muni_sel,
            delito=delito_sel,
            target_year=target_year,
        )
        if pred is None:
            st.warning(str(detail))
        else:
            st.success(
                f"PredicciÃ³n baseline para **{muni_sel}**, delito **{delito_sel}** "
                f"en el aÃ±o **{target_year}**"
            )
            st.metric("Casos estimados (promedio Ãºltimos 3 aÃ±os)", f"{pred:,.0f}")
            st.markdown("**HistÃ³rico usado para el cÃ¡lculo:**")
            st.dataframe(detail.tail(5))


# ============================================================
# 6. MAIN
# ============================================================

def main() -> None:
    st.title("Tablero Inteligente de Seguridad Ciudadana - Santander")

    try:
        data = load_base_tables()
    except Exception as exc:  # noqa: BLE001
        st.error(f"Error cargando los datos: {exc}")
        st.stop()

    metas = data["metas"]
    mandatos = data["mandatos"]
    poblacion = data["poblacion"]
    policia = data["policia"]
    municipios = data["municipios"]

    df_integrated = build_integrated_df(metas, mandatos, poblacion, policia, municipios)

    tab1, tab2, tab3 = st.tabs(
        [
            "ðŸ“Š Dashboard",
            "ðŸ¤– Chatbot comunitario",
            "ðŸ”® Modelo predictivo",
        ]
    )

    with tab1:
        dashboard_tab(df_integrated, mandatos)

    with tab2:
        chatbot_tab(df_integrated)

    with tab3:
        prediction_tab(df_integrated)


if __name__ == "__main__":
    main()
